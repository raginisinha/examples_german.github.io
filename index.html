<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Center Aligned Title</title>
<style>
    body {
        margin: 0 auto;
        max-width: 950px; /* Adjust as needed */
        padding: 20px;
    }
    h1 {
        text-align: center;
    }
    .container {
        display: flex;
        justify-content: space-between;
        margin-top: 20px;
    }
    .audio-column {
        flex: 1;
        margin: 0 10px;
        text-align: left;
		margin-bottom: 20px;
    }
    img {
        width: 100%;
        margin-top: 10px;
    }
</style>
</head>
<body>
<h1>Evaluating Speaker-conditioned Target Speaker Extraction Algorithms for Hearing-Impaired Listeners</h1>
<section>
    <center>Ragini Sinha, Ann-Christin Scherer, Simon Doclo, Christian Rollwage, Jan Rennies</center>
	
    <p><b>Abstract:</b>Speaker-conditioned target speaker extraction algorithms aim at estimating the target speaker from a mixture of multiple speakers utilizing auxiliary information about the target speaker. Previous studies evaluated the performance of such algorithms based on either instrumental measures or subjective evaluation with normal-hearing listeners. This study investigated the subjective performance with hearing-impaired listeners for two different conditions. First, when no hearing loss compensation was provided to the listeners (unaided condition), and second, when a linear hearing loss compensation was provided (aided condition). Three different subjective performance measurement methods were employed to evaluate two different deep neural network-based target speaker extraction algorithms, namely: paired comparison, speech intelligibility measurement, and categorically scaled listening effort. The subjective evaluation results with fifteen hearing-impaired listeners showed significantly lower listening effort and better intelligibility when utilizing one of the considered algorithms compared to the unprocessed stimuli and the other algorithm. The same algorithm was also preferred in direct comparison. The data suggests that hearing-impaired listeners experience even better reduction of listening effort and greater improvement in speech recognition thresholds than normal-hearing listeners.</p>
  </section>

<h1>Audio examples (German matrix sentences)</h1>
<center>Both algorithms were trained on the WSJ0 dataset (English) with 101 different speakers</center>
<center><b>One Male Interfering Speaker:</b></center>
<div class="container">
    <div class="audio-column">
		<center><p>Unprocessed</p></center>
        <audio controls>
            <source src="03491_3_1male_unp.wav" type="audio/wav">
            Your browser does not support the audio element.
        </audio>
        
    </div>
    <div class="audio-column">
		<center><p>Algo-1</center></p>
        <audio controls>
            <source src="03491_3_1male_algo1.wav" type="audio/wav">
            Your browser does not support the audio element.
        </audio>
        
    </div>
    <div class="audio-column">
		<center><p>Algo-2</center></p>
        <audio controls>
            <source src="03491_3_1male_algo2.wav" type="audio/wav">
            Your browser does not support the audio element.
        </audio>
        
    </div>
</div>

<center><b>One Female Interfering Speaker:</b></center>
<div class="container">
    <div class="audio-column">
		<center><p>Unprocessed</center></p>
        <audio controls>
            <source src="F_74972_9_unp.wav" type="audio/wav">
            Your browser does not support the audio element.
        </audio>
        
    </div>
    <div class="audio-column">
		<center><p>Algo-1</center></p>
        <audio controls>
            <source src="F_74972_9_algo1.wav" type="audio/wav">
            Your browser does not support the audio element.
        </audio>
        
    </div>
    <div class="audio-column">
		<center><p>Algo-2</center></p>
        <audio controls>
            <source src="F_74972_9_algo2.wav" type="audio/wav">
            Your browser does not support the audio element.
        </audio>
        
    </div>
</div>

<center><b>Two Male Interfering Speakers:</b></center>
<div class="container">
    <div class="audio-column">
		<center><p>Unprocessed</center></p>
        <audio controls>
            <source src="74972_8_2male_unp.wav" type="audio/wav">
            Your browser does not support the audio element.
        </audio>
        
    </div>
    <div class="audio-column">
		<center><p>Algo-1</center></p>
        <audio controls>
		
            <source src="74972_8_2male_algo1.wav" type="audio/wav">
            Your browser does not support the audio element.
        </audio>
        
    </div>
    <div class="audio-column">
	
		<center><p>Algo-2</center></p>
        <audio controls>
            <source src="74972_8_2male_algo2.wav" type="audio/wav">
            Your browser does not support the audio element.
        </audio>
        
    </div>
</div>

<center><b>Two Female Interfering Speakers:</b></center>
<div class="container">
    <div class="audio-column">
		<center><p>Unprocessed</center></p>
        <audio controls>
            <source src="FF_47173_5_unp.wav" type="audio/wav">
            Your browser does not support the audio element.
        </audio>
        
    </div>
    <div class="audio-column">
		<center><p>Algo-1</center></p>
        <audio controls>
            <source src="FF_47173_5_algo1.wav" type="audio/wav">
            Your browser does not support the audio element.
        </audio>
        
    </div>
    <div class="audio-column">
		<center><p>Algo-2</center></p>
        <audio controls>
            <source src="FF_47173_5_algo2.wav" type="audio/wav">
            Your browser does not support the audio element.
        </audio>
        
    </div>
</div>

<h1>Objective performance evaluations of Algo-1 and Algo-2:</h1>
<center><p>The results shown here are obtained on test-set of the Librispeech dataset <a href="url">https://www.openslr.org/12</a></p></center>
	<div class="container">
    <div class="audio-column">
		<center><img src="sdr_both.png" alt="SDR"></center>
    </div>
    <div class="audio-column">
        <center><img src="pesq_both.png" alt="PESQ"></center>
    </div>
    <div class="audio-column">
        <center><img src="stoi_both.png" alt="STOI"></center>
    </div>
</div>

<h1>Subjective performance evaluations of Algo-1 and Algo-2 for normal-hearing(NH), and hearing-impaired listeners in both unaided and aided conditions:</h1>
<center><p><b>1. Paired Comparisons: </b> percentage of wins in the paired comparison tests obtained for each pair of the three processing conditions (unprocessed, Algo-1, and Algo-2) for NH and HI listeners for stimuli having one interfering (F/M) and two interfering speaker(s) (FF/MM).</p></center>
	<div>
    <div class="plot">
		<iframe src="PC_algo1vsunpr.html"
			width="100%", height="500px"
			frameboarder="0"></iframe>
    </div>
	<div class="plot">
		<iframe src="PC_algo2vsunpr.html"
			width="100%", height="500px"
			frameboarder="0"></iframe>
    </div>
	<div class="plot">
		<iframe src="PC_algos.html"
			width="100%", height="500px"
			frameboarder="0"></iframe>
    </div>
</div>

<center><p><b>2. Speech Recognition Thresholds: </b> SRTs and corresponding benefits for NH and HI listeners for unprocessed stimuli and stimuli processed using Algo-1, and Algo-2. FF and MM represent two female and male interfering speakers, respectively.</p></center>
	<div>
    <div class="plot">
		<iframe src="srt_plot.html"
			width="100%", height="500px"
			frameboarder="0"></iframe>
    </div>
	<div class="plot">
		<iframe src="srt_plot_improvement.html"
			width="100%", height="500px"
			frameboarder="0"></iframe>
    </div>
</div>

<center><p><b>3. Perceived Listening Effort: </b> perceived listening effort ratings and corresponding benefits for NH and HI listeners for unprocessed stimuli having one interfering speaker (F/M) and two interfering speakers (FF/MM) and stimuli processed using Algo-1, and Algo-2. F and M represents gender of the interfering speaker(s), F: female and M: male.</p></center>
	<div>
    <div class="plot">
		<iframe src="le_plot.html"
			width="100%", height="900px"
			frameboarder="0"></iframe>
    </div>
	<div class="plot">
		<iframe src="le_plot_effort.html"
			width="100%", height="500px"
			frameboarder="0"></iframe>
    </div>
</div>
</body>
</html>

